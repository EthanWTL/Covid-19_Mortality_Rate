{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bea1be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ethan\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#load all necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_probability as tfp\n",
    "import edward2 as ed\n",
    "tfd = tfp.distributions\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "sns.set()\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "np.random.seed(111)\n",
    "tf.set_random_seed(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b8a453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../TrainTestData/com_train.csv')\n",
    "test = pd.read_csv('../TrainTestData/com_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "991082b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split, normalize the train-test data\n",
    "def preprocess(train,test):    \n",
    "    x = train.iloc[:,:35]\n",
    "    y = train.iloc[:,35]\n",
    "    x_val = test.iloc[:,:35]\n",
    "    y_val = test.iloc[:,35]\n",
    "    \n",
    "    temp = x.astype('float32')\n",
    "    x = temp.copy()\n",
    "    \n",
    "    temp_val = x_val.astype('float32')\n",
    "    x_val = temp_val.copy()\n",
    "    \n",
    "    y = y.values\n",
    "    y = y.reshape(-1,1)\n",
    "    y_val = y_val.values\n",
    "    y_val = y_val.reshape(-1,1)\n",
    "    y_unnormed = y_val.copy()\n",
    "    \n",
    "    return x,y,x_val,y_val,y_unnormed\n",
    "\n",
    "x,y,x_val,y_val,y_unnormed = preprocess(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ae9099",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = x.shape[1]\n",
    "N = x.shape[0]\n",
    "noise_std_true = 1.0\n",
    "#define y ~ N(coeffs * x + bias , noise)\n",
    "def linear_regression(features):\n",
    "    D = features.shape[1]  \n",
    "    # coefficients: (D,1)\n",
    "    coeffs = ed.Normal(loc=tf.zeros([D,1]),scale=tf.ones([D,1]),name=\"coeffs\")\n",
    "    #bias: (1)\n",
    "    bias = ed.Normal(loc=tf.zeros([1]), scale=tf.ones([1]),name=\"bias\") \n",
    "    #noise: (1)\n",
    "    noise_std = ed.HalfNormal(scale=tf.ones([1]),name=\"noise_std\")\n",
    "    # prediction: y ~ N(coeffs * x + bias , noise)\n",
    "    predictions = ed.Normal(loc=tf.matmul(features, coeffs)+bias,scale=noise_std,name=\"predictions\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8dca864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create log joint probability function \n",
    "log_joint = ed.make_log_joint_fn(linear_regression)\n",
    "def target_log_prob_fn(coeffs, bias, noise_std):\n",
    "    return log_joint(\n",
    "        features=x, \n",
    "        coeffs=coeffs, bias=bias, noise_std=noise_std, \n",
    "        predictions=y\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efdd851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of total iterations\n",
    "num_results = int(5e3) \n",
    "#number of burn-in steps\n",
    "n_burnin = int(2.5e3)\n",
    "#stepsize for leapfrog method\n",
    "step_size = 0.01\n",
    "# Parameter sizes\n",
    "coeffs_size = [D,1]\n",
    "bias_size = [1]\n",
    "noise_std_size = [1]\n",
    "\n",
    "#define the NUTS sampler as kernel\n",
    "kernel = tfp.mcmc.NoUTurnSampler(\n",
    "    target_log_prob_fn=target_log_prob_fn,\n",
    "    step_size=step_size)\n",
    "\n",
    "#create the sample chain\n",
    "states, kernel_results = tfp.mcmc.sample_chain(\n",
    "    num_results=num_results,\n",
    "    num_burnin_steps=n_burnin,\n",
    "    kernel=kernel,\n",
    "    current_state=[\n",
    "        tf.zeros(coeffs_size, name='init_coeffs'),\n",
    "        tf.zeros(bias_size, name='init_bias'),\n",
    "        tf.ones(noise_std_size, name='init_noise_std'),\n",
    "    ])\n",
    "coeffs, bias, noise_std = states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81696284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 279.45s\n"
     ]
    }
   ],
   "source": [
    "class Timer:\n",
    "    def __enter__(self):\n",
    "        self.t0 = time.time()\n",
    "    def __exit__(self, *args):\n",
    "        print('Elapsed time: %0.2fs' % (time.time()-self.t0))\n",
    "        \n",
    "#run the chain\n",
    "with Timer(), tf.Session() as sess:\n",
    "  [\n",
    "      coeffs_,\n",
    "      bias_,\n",
    "      noise_std_,\n",
    "      is_accepted_,\n",
    "  ] = sess.run([\n",
    "      coeffs,\n",
    "      bias,\n",
    "      noise_std,\n",
    "      kernel_results.is_accepted,\n",
    "  ])\n",
    "\n",
    "# Samples after burn-in\n",
    "coeffs_samples = coeffs_[n_burnin:,:,0]\n",
    "bias_samples = bias_[n_burnin:]\n",
    "noise_std_samples = noise_std_[n_burnin:]\n",
    "accepted_samples = is_accepted_[n_burnin:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4245e6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accepted_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19bf5e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acceptance rate: 0.0%\n"
     ]
    }
   ],
   "source": [
    "#check for acceptance rate\n",
    "print('Acceptance rate: %0.1f%%' % (100*np.mean(accepted_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "573278d6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(0, slice(None, None, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU3090\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(0, slice(None, None, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m prediction_distribution \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((N_val, Nmcmc))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_val):\n\u001b[1;32m---> 14\u001b[0m     prediction_distribution[i,:] \u001b[38;5;241m=\u001b[39m ind_pred_dist(\u001b[43mx_val\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Plot random datapoints and their prediction intervals\u001b[39;00m\n\u001b[0;32m     17\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m, sharex\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU3090\\lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU3090\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU3090\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5974\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5972\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5973\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5974\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (0, slice(None, None, None))"
     ]
    }
   ],
   "source": [
    "def ind_pred_dist(X):\n",
    "    '''Compute the prediction distribution'''\n",
    "    predictions = (np.matmul(X, coeffs_samples.transpose()) + \n",
    "                 bias_samples[:,0])\n",
    "    noise = (noise_std_samples[:,0] * \n",
    "           np.random.randn(noise_std_samples.shape[0]))\n",
    "    return predictions + noise\n",
    "\n",
    "# Compute prediction distribution for all validation samples\n",
    "N_val = y_val.shape[0]\n",
    "Nmcmc = coeffs_samples.shape[0]\n",
    "prediction_distribution = np.zeros((N_val, Nmcmc))\n",
    "for i in range(N_val):\n",
    "    prediction_distribution[i,:] = ind_pred_dist(x_val[i,:])\n",
    "\n",
    "# Plot random datapoints and their prediction intervals\n",
    "fig, axes = plt.subplots(4, 2, sharex='all')\n",
    "for i in range(4):\n",
    "    for j in range(2):\n",
    "        ix = i*2+j\n",
    "        pred_dist = prediction_distribution[ix,:]\n",
    "        sns.kdeplot(pred_dist, fill=True, ax=axes[i][j])\n",
    "        axes[i][j].axvline(x=y_val[ix,0])\n",
    "    axes[i][0].set_ylabel('p(y)')\n",
    "\n",
    "axes[3][0].set_xlabel('y')\n",
    "axes[3][1].set_xlabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8cd46e1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_distribution' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pred_dist \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_distribution\u001b[49m[\u001b[38;5;241m100\u001b[39m,:]\n\u001b[0;32m      3\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mkdeplot(pred_dist, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction_distribution' is not defined"
     ]
    }
   ],
   "source": [
    "pred_dist = prediction_distribution[100,:]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "sns.kdeplot(pred_dist, fill=True)\n",
    "\n",
    "density, x = sns.kdeplot(pred_dist, fill=False).get_lines()[0].get_data()\n",
    "f = interp1d(density, x)\n",
    "y = f(y_val[100,0])\n",
    "print('Probability of wine quality as {} is {:0.2f}%'.format(y_unnormed[100,0],y*100))\n",
    "ax.axvline(x=y_val[100,0])\n",
    "ax.axvline(np.quantile(pred_dist, 0.025), color='r', linestyle=\"dashed\")\n",
    "ax.axvline(np.quantile(pred_dist, 0.975), color='r', linestyle=\"dashed\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU3090",
   "language": "python",
   "name": "gpu3090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
