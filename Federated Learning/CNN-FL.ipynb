{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f37971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Activation, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05fdffd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data_files = ['cle_train.csv','cle_test.csv','hun_train.csv','hun_test.csv','swi_train.csv','swi_test.csv','vir_train.csv','vir_test.csv']\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for file in data_files:\n",
    "    data = pd.read_csv('TrainTestData/' + file)\n",
    "    \n",
    "    X = data.iloc[:, :-1]\n",
    "    Y = data.iloc[:, -1]\n",
    "    \n",
    "    Y_binary = Y.apply(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    # Extract the name from the file path\n",
    "    name = file.split('.')[0]\n",
    "    \n",
    "    # Store the dataset components in a dictionary\n",
    "    datasets[name] = {'X': X, 'Y': Y, 'Y_binary': Y_binary}\n",
    "\n",
    "# Unpack the dictionary values in a loop\n",
    "variables = ['cle', 'hun', 'swi', 'vir']\n",
    "train_test = ['train', 'test']\n",
    "\n",
    "for var in variables:\n",
    "    for tt in train_test:\n",
    "        X, Y, Y_binary = datasets[f'{var}_{tt}'].values()\n",
    "        globals()[f'{var}_X_{tt}'] = X\n",
    "        globals()[f'{var}_Y_{tt}'] = Y\n",
    "        globals()[f'{var}_Y_{tt}_binary'] = Y_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8171119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat([cle_X_test,hun_X_test,swi_X_test,vir_X_test])\n",
    "y_test = pd.concat([cle_Y_test_binary,hun_Y_test_binary,swi_Y_test_binary,vir_Y_test_binary])\n",
    "\n",
    "X_train = pd.concat([cle_X_train,hun_X_train,swi_X_train,vir_X_train])\n",
    "y_train = pd.concat([cle_Y_train_binary,hun_Y_train_binary,swi_Y_train_binary,vir_Y_train_binary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc05e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients():\n",
    "    cle_zip = list(zip(cle_X_train.values,cle_Y_train_binary))\n",
    "    hun_zip = list(zip(hun_X_train.values,hun_Y_train_binary))\n",
    "    vir_zip = list(zip(vir_X_train.values,vir_Y_train_binary))\n",
    "    swi_zip = list(zip(swi_X_train.values,swi_Y_train_binary))\n",
    "    \n",
    "    shards = [cle_zip, hun_zip, vir_zip,swi_zip]\n",
    "    client_names = [\"client_1\",\"client_2\",\"client_3\",\"client_4\"]\n",
    "    dic = {client_names[i] : shards[i] for i in range(len(client_names))}\n",
    "    return dic\n",
    "\n",
    "\n",
    "def batch_data(data_shard, bs=32):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)\n",
    "\n",
    "\n",
    "class CNN:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(20,1)))\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "        model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    #logits = model.predict(X_test, batch_size=100)\n",
    "    logits = model.predict(X_test)\n",
    "    length = len(y_test)\n",
    "    Y_test = tf.reshape(Y_test,(length,1))\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), Y_test)\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c94fcc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\GPU\\lib\\site-packages\\keras\\optimizers\\legacy\\gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 0 | global_acc: 60.302% | global_loss: 0.6685662269592285\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 1 | global_acc: 73.010% | global_loss: 0.6253419518470764\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 2 | global_acc: 74.593% | global_loss: 0.6112122535705566\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 3 | global_acc: 74.945% | global_loss: 0.606839120388031\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 4 | global_acc: 74.150% | global_loss: 0.6079518795013428\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 5 | global_acc: 75.437% | global_loss: 0.6099951863288879\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 6 | global_acc: 75.488% | global_loss: 0.6116540431976318\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 7 | global_acc: 75.354% | global_loss: 0.6058533191680908\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 8 | global_acc: 75.601% | global_loss: 0.609203040599823\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 9 | global_acc: 75.603% | global_loss: 0.6082653999328613\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 10 | global_acc: 75.351% | global_loss: 0.6069087386131287\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 11 | global_acc: 75.703% | global_loss: 0.6096991300582886\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 12 | global_acc: 75.508% | global_loss: 0.6051813960075378\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 13 | global_acc: 75.631% | global_loss: 0.6059659719467163\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 14 | global_acc: 75.585% | global_loss: 0.6064825654029846\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 15 | global_acc: 75.696% | global_loss: 0.6054362654685974\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 16 | global_acc: 75.760% | global_loss: 0.605891227722168\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 17 | global_acc: 75.684% | global_loss: 0.607322096824646\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 18 | global_acc: 75.832% | global_loss: 0.6087285280227661\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 19 | global_acc: 75.788% | global_loss: 0.6060912609100342\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 20 | global_acc: 75.783% | global_loss: 0.606256365776062\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 21 | global_acc: 75.827% | global_loss: 0.6057289242744446\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 22 | global_acc: 75.756% | global_loss: 0.6073511838912964\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 23 | global_acc: 75.753% | global_loss: 0.6060103178024292\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 24 | global_acc: 75.751% | global_loss: 0.6063010096549988\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 25 | global_acc: 75.804% | global_loss: 0.6053874492645264\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 26 | global_acc: 75.809% | global_loss: 0.605945348739624\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 27 | global_acc: 75.798% | global_loss: 0.6061686873435974\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 28 | global_acc: 75.894% | global_loss: 0.6061332821846008\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 29 | global_acc: 75.846% | global_loss: 0.6052670478820801\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 30 | global_acc: 75.871% | global_loss: 0.6063515543937683\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 31 | global_acc: 75.867% | global_loss: 0.6046004295349121\n",
      "1773/1773 [==============================] - 3s 1ms/step\n",
      "comm_round: 32 | global_acc: 75.857% | global_loss: 0.6060060262680054\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 33 | global_acc: 75.816% | global_loss: 0.6058254837989807\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 34 | global_acc: 75.862% | global_loss: 0.6071323156356812\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 35 | global_acc: 75.790% | global_loss: 0.6055558323860168\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 36 | global_acc: 75.924% | global_loss: 0.6054669618606567\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 37 | global_acc: 75.853% | global_loss: 0.6060081124305725\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 38 | global_acc: 75.848% | global_loss: 0.6060880422592163\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 39 | global_acc: 75.872% | global_loss: 0.6044532060623169\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 40 | global_acc: 75.946% | global_loss: 0.6061933040618896\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 41 | global_acc: 75.901% | global_loss: 0.6058756709098816\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 42 | global_acc: 75.869% | global_loss: 0.6057434678077698\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 43 | global_acc: 75.927% | global_loss: 0.6051002740859985\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 44 | global_acc: 75.938% | global_loss: 0.605858564376831\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 45 | global_acc: 75.929% | global_loss: 0.6036601662635803\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 46 | global_acc: 75.890% | global_loss: 0.6052170395851135\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 47 | global_acc: 75.943% | global_loss: 0.6067561507225037\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 48 | global_acc: 75.924% | global_loss: 0.6056857705116272\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 49 | global_acc: 75.924% | global_loss: 0.6047896146774292\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 50 | global_acc: 75.927% | global_loss: 0.6040993332862854\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 51 | global_acc: 75.962% | global_loss: 0.6047968864440918\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 52 | global_acc: 75.955% | global_loss: 0.6036930084228516\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 53 | global_acc: 75.938% | global_loss: 0.6051162481307983\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 54 | global_acc: 75.998% | global_loss: 0.6056157946586609\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 55 | global_acc: 75.978% | global_loss: 0.6070910096168518\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 56 | global_acc: 75.938% | global_loss: 0.6044520735740662\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 57 | global_acc: 75.980% | global_loss: 0.6049872040748596\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 58 | global_acc: 75.948% | global_loss: 0.6058276891708374\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 59 | global_acc: 76.012% | global_loss: 0.6064806580543518\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 60 | global_acc: 75.957% | global_loss: 0.6047602295875549\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 61 | global_acc: 75.887% | global_loss: 0.6053573489189148\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 62 | global_acc: 75.973% | global_loss: 0.6052426695823669\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 63 | global_acc: 75.865% | global_loss: 0.6031050086021423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 64 | global_acc: 75.994% | global_loss: 0.6071088910102844\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 65 | global_acc: 75.957% | global_loss: 0.6060611605644226\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 66 | global_acc: 75.945% | global_loss: 0.604714572429657\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 67 | global_acc: 75.984% | global_loss: 0.6053755283355713\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 68 | global_acc: 75.931% | global_loss: 0.6042124629020691\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 69 | global_acc: 75.932% | global_loss: 0.6033385396003723\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 70 | global_acc: 75.941% | global_loss: 0.6044416427612305\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 71 | global_acc: 75.992% | global_loss: 0.60598224401474\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 72 | global_acc: 75.992% | global_loss: 0.6057431697845459\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 73 | global_acc: 75.992% | global_loss: 0.6041150093078613\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 74 | global_acc: 76.015% | global_loss: 0.605250358581543\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 75 | global_acc: 76.005% | global_loss: 0.605467677116394\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 76 | global_acc: 75.999% | global_loss: 0.6044032573699951\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 77 | global_acc: 76.008% | global_loss: 0.6044536232948303\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 78 | global_acc: 75.890% | global_loss: 0.6051070690155029\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 79 | global_acc: 75.989% | global_loss: 0.6044787168502808\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 80 | global_acc: 75.964% | global_loss: 0.6053916215896606\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 81 | global_acc: 76.013% | global_loss: 0.6039576530456543\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 82 | global_acc: 76.015% | global_loss: 0.60527104139328\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 83 | global_acc: 76.003% | global_loss: 0.6052627563476562\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 84 | global_acc: 76.022% | global_loss: 0.6049671173095703\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 85 | global_acc: 75.989% | global_loss: 0.6046727299690247\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 86 | global_acc: 75.994% | global_loss: 0.6044270396232605\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 87 | global_acc: 76.015% | global_loss: 0.603435754776001\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 88 | global_acc: 76.038% | global_loss: 0.6047135591506958\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 89 | global_acc: 76.015% | global_loss: 0.6055607199668884\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 90 | global_acc: 76.028% | global_loss: 0.6044166684150696\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 91 | global_acc: 76.012% | global_loss: 0.6046993732452393\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 92 | global_acc: 76.042% | global_loss: 0.6041373610496521\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 93 | global_acc: 76.008% | global_loss: 0.6046547889709473\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 94 | global_acc: 76.043% | global_loss: 0.6039524674415588\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 95 | global_acc: 75.999% | global_loss: 0.6057997941970825\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 96 | global_acc: 76.022% | global_loss: 0.6057038307189941\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 97 | global_acc: 76.052% | global_loss: 0.6045917868614197\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 98 | global_acc: 76.026% | global_loss: 0.6047616004943848\n",
      "1773/1773 [==============================] - 2s 1ms/step\n",
      "comm_round: 99 | global_acc: 76.010% | global_loss: 0.604241669178009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m         SGD_model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mloss, optimizer\u001b[38;5;241m=\u001b[39moptimizer, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# fit the SGD training data to model\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mSGD_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSGD_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m#test the SGD global model and print out metrics\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m(X_test, Y_test) \u001b[38;5;129;01min\u001b[39;00m test_batched:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\GPU\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#create clients\n",
    "clients = create_clients()\n",
    "\n",
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))\n",
    "\n",
    "comms_round = 100\n",
    "    \n",
    "#create optimizer\n",
    "lr = 0.01 \n",
    "loss='sparse_categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(lr=lr, decay=lr / comms_round, momentum=0.9) \n",
    "\n",
    "#initialize global model\n",
    "smlp_global = CNN()\n",
    "global_model = smlp_global.build(20, 2)\n",
    "        \n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = CNN()\n",
    "        local_model = smlp_local.build(20, 2)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "        SGD_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(250)\n",
    "        smlp_SGD = CNN()\n",
    "        SGD_model = smlp_SGD.build(20, 2) \n",
    "\n",
    "        SGD_model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "# fit the SGD training data to model\n",
    "_ = SGD_model.fit(SGD_dataset, epochs=100, verbose=0)\n",
    "\n",
    "#test the SGD global model and print out metrics\n",
    "for(X_test, Y_test) in test_batched:\n",
    "        SGD_acc, SGD_loss = test_model(X_test, Y_test, SGD_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b13ff1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773/1773 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "Y_predictions = np.argmax(SGD_model.predict(X_test),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bc551a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25832,  6824],\n",
       "       [ 8381, 15699]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_predictions, Y_test)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a83e0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7910    0.7550    0.7726     34213\n",
      "           1     0.6520    0.6970    0.6737     22523\n",
      "\n",
      "    accuracy                         0.7320     56736\n",
      "   macro avg     0.7215    0.7260    0.7232     56736\n",
      "weighted avg     0.7358    0.7320    0.7334     56736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56495b0e",
   "metadata": {},
   "source": [
    "# Testing on each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec02651a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 1s 1ms/step\n",
      "[[6474 1727]\n",
      " [2061 3922]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7585    0.7894    0.7737      8201\n",
      "           1     0.6943    0.6555    0.6743      5983\n",
      "\n",
      "    accuracy                         0.7329     14184\n",
      "   macro avg     0.7264    0.7225    0.7240     14184\n",
      "weighted avg     0.7314    0.7329    0.7318     14184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_cle = np.argmax(SGD_model.predict(cle_X_test),axis = 1)\n",
    "cm_cle = confusion_matrix(Y_cle, cle_Y_test_binary)\n",
    "print(cm_cle)\n",
    "print(classification_report(Y_cle, cle_Y_test_binary, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b7cedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 10, 19, 22, 28, 32, 38, 43, 46, 53, 67, 68, 69, 70, 77, 90]\n"
     ]
    }
   ],
   "source": [
    "mismatch = [i for i, (a,b) in enumerate(zip(Y_cle, cle_Y_test_binary)) if a != b]\n",
    "print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2d4cc1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 1s 1ms/step\n",
      "[[6597 1674]\n",
      " [2050 3863]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7629    0.7976    0.7799      8271\n",
      "           1     0.6977    0.6533    0.6748      5913\n",
      "\n",
      "    accuracy                         0.7375     14184\n",
      "   macro avg     0.7303    0.7255    0.7273     14184\n",
      "weighted avg     0.7357    0.7375    0.7361     14184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_vir = np.argmax(SGD_model.predict(vir_X_test),axis = 1)\n",
    "cm_vir = confusion_matrix(Y_vir, vir_Y_test_binary)\n",
    "print(cm_vir)\n",
    "print(classification_report(Y_vir, vir_Y_test_binary, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "625cfaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 6, 11, 14, 22, 32, 34, 40, 48, 49, 56, 58]\n"
     ]
    }
   ],
   "source": [
    "mismatch = [i for i, (a,b) in enumerate(zip(Y_vir, vir_Y_test_binary)) if a != b]\n",
    "print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c031520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 1s 1ms/step\n",
      "[[6414 1692]\n",
      " [2127 3951]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7510    0.7913    0.7706      8106\n",
      "           1     0.7002    0.6500    0.6742      6078\n",
      "\n",
      "    accuracy                         0.7308     14184\n",
      "   macro avg     0.7256    0.7207    0.7224     14184\n",
      "weighted avg     0.7292    0.7308    0.7293     14184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_hun = np.argmax(SGD_model.predict(hun_X_test),axis = 1)\n",
    "cm_hun = confusion_matrix(Y_hun, hun_Y_test_binary)\n",
    "print(cm_hun)\n",
    "print(classification_report(Y_hun, hun_Y_test_binary, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec7ffbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 13, 14, 23, 29, 36, 42, 45, 46, 54]\n"
     ]
    }
   ],
   "source": [
    "mismatch = [i for i, (a,b) in enumerate(zip(Y_hun, hun_Y_test_binary)) if a != b]\n",
    "print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e837211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 1s 1ms/step\n",
      "[[6347 1731]\n",
      " [2143 3963]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7476    0.7857    0.7662      8078\n",
      "           1     0.6960    0.6490    0.6717      6106\n",
      "\n",
      "    accuracy                         0.7269     14184\n",
      "   macro avg     0.7218    0.7174    0.7189     14184\n",
      "weighted avg     0.7254    0.7269    0.7255     14184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_swi = np.argmax(SGD_model.predict(swi_X_test),axis = 1)\n",
    "cm_swi = confusion_matrix(Y_swi, swi_Y_test_binary)\n",
    "print(cm_swi)\n",
    "print(classification_report(Y_swi, swi_Y_test_binary, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "805b6caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 6, 20, 27]\n"
     ]
    }
   ],
   "source": [
    "mismatch = [i for i, (a,b) in enumerate(zip(Y_swi, swi_Y_test_binary)) if a != b]\n",
    "print(mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd924b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
